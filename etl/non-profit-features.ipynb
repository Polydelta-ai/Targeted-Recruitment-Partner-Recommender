{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import necessary libraries\n",
    "import pandas as pd\n",
    "from googlesearch import search\n",
    "from time import sleep\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set pandas options \n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.colheader_justify', 'center')\n",
    "pd.set_option('display.precision', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to create vector\n",
    "def get_dict(filename):\n",
    "    \n",
    "    df = pd.read_csv(filename, names = ['code', 'description'])\n",
    "    df = df.iloc[1:]\n",
    "    ndx = df['code'].to_list()\n",
    "    s = df['description']\n",
    "    s.index = ndx\n",
    "    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop orgs that are not relevant and create keyword list\n",
    "def search_keywords(keywords_list, df):\n",
    "\n",
    "    if len(keywords_list) > 0: \n",
    "        keyword_search_strings = [f\"(df.NAME.str.contains('{keyword.upper()}'))\" for keyword in keywords_list]\n",
    "        query = \" | \".join(keyword_search_strings)\n",
    "        df = df[eval(query)]\n",
    "    \n",
    "    df = df[~df.NAME.str.contains(\"FOUNDATION\")]\n",
    "    df = df[~df.NAME.str.contains(\"TRUST\")] \n",
    "    df = df[~df.NAME.str.contains(\"DISTRICT\")]\n",
    "    df = df[~df.NAME.str.contains(\"LOAVES\")] \n",
    "    df = df[~df.NAME.str.contains(\"DEVELOPMENT\")] \n",
    "    df = df[~df.NAME.str.contains(\"CONSERVANCY\")] \n",
    "    df = df[~df.NAME.str.contains(\"PROPERTY\")] \n",
    "    df = df[~df.NAME.str.contains(\"FUND\")] \n",
    "    df = df[~df.NAME.str.contains(\"HOMEOWNERS\")] \n",
    "    df = df[~df.NAME.str.contains(\"SCHOOL\")] \n",
    "    df = df[~df.NAME.str.endswith(\" TR\")] \n",
    "    \n",
    " \n",
    "    df = df[~df.NTEEFINAL.str.contains('J01')] # Advocacy and alliance\n",
    "    df = df[~df.NTEEFINAL.str.contains('K01')] # Advocacy and alliance\n",
    "    df = df[~df.NTEEFINAL.str.contains('T01')] # Advocacy and alliance\n",
    "    df = df[~df.NTEEFINAL.str.contains('U01')] # Advocacy and alliance\n",
    "    df = df[~df.NTEEFINAL.str.contains('V01')] # Advocacy and alliance\n",
    "    df = df[~df.NTEEFINAL.str.contains('Y01')] # Advocacy and alliance\n",
    "    df = df[~df.NTEEFINAL.str.contains('C02')] # Management and technical assistance\n",
    "    df = df[~df.NTEEFINAL.str.contains('D02')] # Management and technical assistance\n",
    "    df = df[~df.NTEEFINAL.str.contains('J02')] # Management and technical assistance\n",
    "    df = df[~df.NTEEFINAL.str.contains('K02')] # Management and technical assistance\n",
    "    df = df[~df.NTEEFINAL.str.contains('T02')] # Management and technical assistance\n",
    "    df = df[~df.NTEEFINAL.str.contains('U02')] # Management and technical assistance\n",
    "    df = df[~df.NTEEFINAL.str.contains('V02')] # Management and technical assistance\n",
    "    df = df[~df.NTEEFINAL.str.contains('Y02')] # Management and technical assistance\n",
    "    df = df[~df.NTEEFINAL.str.contains('C12')] # Fundraising and distribution\n",
    "    df = df[~df.NTEEFINAL.str.contains('D12')] # Fundraising and distribution\n",
    "    df = df[~df.NTEEFINAL.str.contains('J12')] # Fundraising and distribution\n",
    "    df = df[~df.NTEEFINAL.str.contains('K12')] # Fundraising and distribution\n",
    "    df = df[~df.NTEEFINAL.str.contains('T12')] # Fundraising and distribution\n",
    "    df = df[~df.NTEEFINAL.str.contains('U12')] # Fundraising and distribution\n",
    "    df = df[~df.NTEEFINAL.str.contains('V12')] # Fundraising and distribution\n",
    "    df = df[~df.NTEEFINAL.str.contains('Y12')] # Fundraising and distribution\n",
    "    df = df[~df.NTEEFINAL.str.contains('D50')] # Drop zoos and acquariams\n",
    "    df = df[~df.NTEEFINAL.str.contains('D20')] # Animal welfare\n",
    "    df = df[~df.NTEEFINAL.str.contains('D61')] # Animal training\n",
    "    df = df[~df.NTEEFINAL.str.contains('K30')] # Free or low-cost food programs\n",
    "    df = df[~df.NTEEFINAL.str.contains('K34')] # Congrete meals\n",
    "    df = df[~df.NTEEFINAL.str.contains('K35')] # Soup kitchens\n",
    "    df = df[~df.NTEEFINAL.str.contains('K36')] # Meals on wheels\n",
    "    df = df[~df.NTEEFINAL.str.contains('K6A')] # Meat markets\n",
    "    df = df[~df.NTEEFINAL.str.contains('K6B')] # Confectionary & nut stores\n",
    "    df = df[~df.NTEEFINAL.str.contains('K6C')] # Caterers\n",
    "    df = df[~df.NTEEFINAL.str.contains('K6D')] # Mobile food service\n",
    "    df = df[~df.NTEEFINAL.str.contains('K6E')] # Bars\n",
    "    df = df[~df.NTEEFINAL.str.contains('K6F')] # Snack bars\n",
    "    df = df[~df.NTEEFINAL.str.contains('K90')] # Restaurants\n",
    "    df = df[~df.NTEEFINAL.str.contains('K91')] # Supermarkets\n",
    "    df = df[~df.NTEEFINAL.str.contains('K92')] # Convience stores\n",
    "    df = df[~df.NTEEFINAL.str.contains('K93')] # Fruit market\n",
    "    df = df[~df.NTEEFINAL.str.contains('K94')] # Specialty foods\n",
    "    df = df[~df.NTEEFINAL.str.contains('K95')] # Supplement stores\n",
    "    df = df[~df.NTEEFINAL.str.contains('K96')] # Warehouses and wholesale\n",
    "    df = df[~df.NTEEFINAL.str.contains('K97')] # Food contractors\n",
    "    df = df[~df.NTEEFINAL.str.contains('K98')] # Restaurants\n",
    "    df = df[~df.NTEEFINAL.str.contains('U31')] # Astronomy\n",
    "    df = df[~df.NTEEFINAL.str.contains('V22')] # Economics\n",
    "    df = df[~df.NTEEFINAL.str.contains('V23')] # Behavioral science\n",
    "    df = df[~df.NTEEFINAL.str.contains('V24')] # Poli sci\n",
    "    df = df[~df.NTEEFINAL.str.contains('V25')] # Population studies\n",
    "    df = df[~df.NTEEFINAL.str.contains('V26')] # Law\n",
    "    df = df[~df.NTEEFINAL.str.contains('V36')] # Gerontology\n",
    "    df = df[~df.NTEEFINAL.str.contains('Y20')] # Insurance\n",
    "    df = df[~df.NTEEFINAL.str.contains('Y22')] # Life Insurance\n",
    "    df = df[~df.NTEEFINAL.str.contains('Y23')] # Mutual Insurance\n",
    "    df = df[~df.NTEEFINAL.str.contains('Y25')] # Workers comp\n",
    "    df = df[~df.NTEEFINAL.str.contains('Y34')] # Pension trust\n",
    "    df = df[~df.NTEEFINAL.str.contains('Y35')] # Multi employer pension plans\n",
    "    df = df[~df.NTEEFINAL.str.contains('Y50')] # Cemeteries\n",
    "\n",
    "\n",
    "    professional_org_words = [\n",
    "        'association',\n",
    "        'assn',\n",
    "        'council',\n",
    "        'federation',\n",
    "        'society',\n",
    "        'corps',\n",
    "    ]\n",
    "\n",
    "    professional_query = [f\"(df.NAME.str.contains('{keyword.upper()}'))\" for keyword in professional_org_words]\n",
    "    query = \" | \".join(professional_query)\n",
    "    df = df[eval(query)]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save df as CSV and filter based on 'ASSETS' and 'INCOME'\n",
    "df = pd.read_csv(\"../data/non_profit_data.csv\")\n",
    "df.drop_duplicates(inplace = True, subset=['NAME'])\n",
    "df = df[df.ASSETS > 10000]\n",
    "df = df[df.INCOME > 50000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create major groups list and drop irrelevants\n",
    "major_groups =[\n",
    "['A', 'A-Arts, Culture & Humanities'],\n",
    "['B', 'B-Education'],\n",
    "['BH', 'BH-Higher educ.'],\n",
    "# ['C', 'C-Environment'],\n",
    "# ['D', 'D-Animal Related'],\n",
    "['E', 'E-Health - General'],\n",
    "['EH', 'EH-Hospitals'],\n",
    "['F', 'F-Mental Health'],\n",
    "['G', 'G-Health - Disease Specific (general)'],\n",
    "['H', 'H-Health - Disease Specific (research)'],\n",
    "['I', 'I-Crime, Legal Related'],\n",
    "# ['J', 'J-Employment, Job Related'],\n",
    "# ['K', 'K-Food, Agriculture, Nutrition'],\n",
    "['L', 'L-Housing, Shelter'],\n",
    "['M', 'M-Public Safety, Disaster Preparedness'],\n",
    "['N', 'N-Recreation and Sports'],\n",
    "['O', 'O-Youth Development'],\n",
    "['P', 'P-Human Services, Multipurpose and Other'],\n",
    "['Q', 'Q-International, Foreign Affairs'],\n",
    "['R', 'R-Civil Rights/Advocacy'],\n",
    "['S', 'S-Community Improvement'],\n",
    "# ['T', 'T-Philanthropy, Voluntarism'],\n",
    "# ['U', 'U-Science and Technology'],\n",
    "# ['V', 'V-Social Science'],\n",
    "['W', 'W-Public, Society Benefit'],\n",
    "['X', 'X-Religion Related'],\n",
    "# ['Y', 'Y-Mutual/Membership Benefit'],\n",
    "['Z', 'Z-Unknown, Unclassified']]\n",
    "\n",
    "drop_major_groups = [group[0] for group in major_groups]\n",
    "string_of_groups = '|'.join(drop_major_groups)\n",
    "df = df.dropna(subset=['MAJGRPB'])\n",
    "df = df[~df.MAJGRPB.str.contains('|'.join(drop_major_groups))]\n",
    "df['MAJGRPB_DES'] = df['MAJGRPB'].replace({major_group[0]:major_group[1] for major_group in major_groups})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create primary codes list and use dict function\n",
    "primary_codes = list(df.MAJGRPB.unique())\n",
    "NTEEFINAL_DICT = get_dict('NTEEFINAL.csv')\n",
    "NTEEFINAL_DICT = {k:v for (k,v) in NTEEFINAL_DICT.items() if any(code in k for code in primary_codes)}\n",
    "NTEEFINAL_DICT.pop('A6C')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create keywords list and search using function\n",
    "keywords = [\n",
    "    'conserv',\n",
    "    'fish',\n",
    "    'wildlife',\n",
    "    'raptor research',\n",
    "    'zoology',\n",
    "    'orthonol',\n",
    "    'waterbird',\n",
    "    'Herpetolog',\n",
    "    'Ichthyolog',\n",
    "    'Entomolog',\n",
    "    'Lake Management',\n",
    "    'Wetland',\n",
    "    'marine',\n",
    "    'aqua',\n",
    "    'animal behavior',\n",
    "    'avian',\n",
    "    'natural resourc',\n",
    "    'husbandry',\n",
    "    'environment',\n",
    "    'animal',\n",
    "    'deer',\n",
    "    'beer',\n",
    "    'biolog',\n",
    "    'chemistry',\n",
    "    'climate',\n",
    "    'ocean',\n",
    "\n",
    "]\n",
    "\n",
    "df = search_keywords(keywords, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save url df as CSV\n",
    "np_url_data = pd.read_csv('../data/url-clean-non-profit.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop NaNs in 'URL' column and reorder columns\n",
    "np_url_data.dropna(subset=[\"URL\"], inplace=True)\n",
    "np_url_data = np_url_data[['EIN',\"URL\"]]\n",
    "np_url_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to scrape urls for orgs that do not have on in df\n",
    "def get_url(series):\n",
    "    try:\n",
    "        result =  np_url_data[np_url_data.EIN == series.EIN].URL.iloc[0]\n",
    "        return result\n",
    "\n",
    "    except:\n",
    "        query = series.NAME.replace(' ','+').replace('+INC','')\n",
    "        return f'https://www.google.com/search?as_epq={query}'\n",
    "\n",
    "df['URL'] = df.apply(get_url, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test\n",
    "len(df[df.URL.str.endswith('.ORG')][['NAME',\"URL\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sort df by 'ASSETS' and 'INCOME' columns\n",
    "code = 'C30'\n",
    "print(NTEEFINAL_DICT[code])\n",
    "df[df.NTEEFINAL == code].sort_values(by=['ASSETS', 'INCOME'], ascending=False)[['NAME',\"URL\",]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student = True\n",
    "majors = False\n",
    "states = ['DC']\n",
    "keywords = None\n",
    "\n",
    "#Function to generate scores for orgs\n",
    "def generate_score(series):\n",
    "\n",
    "    weights = dict(\n",
    "        student = 0.30,\n",
    "        majors = 0.20,\n",
    "        states = 0.25,\n",
    "        keywords = 0.25,\n",
    "\n",
    "        # boost\n",
    "        NTEEFINAL = 0.1,\n",
    "        LARGE_SIZE = 0.1\n",
    "    )\n",
    "\n",
    "    # prepare the date\n",
    "    title_words = series.NAME.split(' ')\n",
    "    student_keywords = ['STUDENT','YOUTH','CHILDREN','TEEN']\n",
    "\n",
    "    # calculate the max possible score given the user query\n",
    "    max_possible_score = 0\n",
    "    if student: max_possible_score += 1 * weights['student']\n",
    "    if states: max_possible_score += 1 * weights['states']\n",
    "    if majors: max_possible_score += 1 * weights['majors']\n",
    "    if keywords: max_possible_score += 1 * weights['keywords']\n",
    "    max_possible_score *= 1 + (weights['NTEEFINAL'] + weights['LARGE_SIZE'])\n",
    "    \n",
    "\n",
    "    # calculate the actual raw score    \n",
    "    score = 0\n",
    "    boost = 0\n",
    "    if any([word.upper() in student_keywords for word in title_words]): score += 1 * weights['student']\n",
    "    if states:\n",
    "        if series.STATE in states: score += 1 * weights['states']\n",
    "    if majors: \n",
    "        if any([word.upper() in majors for word in title_words]): score += 1 * weights['majors']\n",
    "    if keywords: \n",
    "        if any([word.upper() in keywords for word in title_words]): score += 1 * weights['states']\n",
    "    if any([series.NTEEFINAL == \"C03\", series.NTEEFINAL == \"D03\"]): boost += 0.10\n",
    "    if any([series.INCOME > 2000000, series.ASSETS > 10000000]): boost += 0.10\n",
    "    score *= 1 + boost\n",
    "    \n",
    "    # calculate the ranking score\n",
    "    ranking_score = round(score / max_possible_score,2)\n",
    "\n",
    "    return ranking_score\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Map scores to 'SCORE' column\n",
    "df['SCORE'] = df.apply(generate_score, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test\n",
    "query = \"espn\"\n",
    " \n",
    "for j in search(query, tld=\"co.in\", num=1, stop=1, pause=2):\n",
    "    print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create list of org urls to scrape\n",
    "to_scrape = df.NAME.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to create list of urls \n",
    "def url_finder(list):\n",
    "\n",
    "    urls = []\n",
    "\n",
    "    for name in tqdm(list):\n",
    "        if 'www.google.com' not in df[df.NAME == name].iloc[0].URL:\n",
    "            append_url = df[df.NAME == name].iloc[0].URL\n",
    "            urls.append(append_url)\n",
    "        else:\n",
    "            sleep(0.2)\n",
    "            for j in search(name, tld=\"co.in\", num=1, stop=1, pause=2):\n",
    "                urls.append(j.upper())\n",
    "        \n",
    "\n",
    "    return urls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Map list of urls to 'URL' column\n",
    "df['URL'] = urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(20)):\n",
    "    sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reorder df\n",
    "df[[\"NAME\",\"URL\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save df as CSV\n",
    "df.to_csv('../data/non_profit_data_clean.csv')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4efb34fdd44591087287cb647f8e075132d6a6d57ecc05eaa3a80a5de4ea1f8b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
